{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c94759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6017a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow v2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow v{}'.format(tf.__version__))\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "hasGpu = False\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            hasGpu = True\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(hasGpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fab8b",
   "metadata": {},
   "source": [
    "# Data and Preprocessing\n",
    "\n",
    "This dataset consisted of 3 different indicators, EMA14 EMA50 ATR14, each with the previous 5 values at the time of trade entry.  This made for a total of 15 inputs with shape (15,) and containing 3 features.  The label was whether the trade was profitable (0 no, 1 yes).  This is by design so that the deep learning model acts as a `trade filter`.  The trade entry logic is simple `if-then` logic which sends the 3 indicators' previous 5 values as input.  The model takes this input and the prediction is whether the model expects the trade to be profitable (profitable includes anything breakeven or better).  If you receive a prediction of `1`, take the trade.  If you receive a prediction of `0`, you have 2 choices.  Either 1) don't take the trade 2) flip the trade to the opposite direction (go short instead of long, or long instead of short).  A prediction of `0` indicates the model expects the trade to be a losing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fa4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 3\n",
    "time_steps = 5\n",
    "windowSize = time_steps * features\n",
    "batchSize = 16\n",
    "trainingFileName = './TensorFlowFib50StratES 06-21Training.bin'\n",
    "#trainingFileName = 'sonar.csv'\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a30902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build type array which matches NT8 indicators\n",
    "typeArray = []\n",
    "nameArray = []\n",
    "#for i in range (0, windowSize):\n",
    "#    typeArray.append((f'{i}', np.single))\n",
    "\n",
    "for i in range(0, 5):\n",
    "    typeArray.append((f'ema14_{i}', np.single))\n",
    "    nameArray.append((f'ema14_{i}'))\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    typeArray.append((f'ema50_{i}', np.single))\n",
    "    nameArray.append((f'ema50_{i}'))\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    typeArray.append((f'atr14_{i}', np.single))\n",
    "    nameArray.append((f'atr14_{i}'))\n",
    "\n",
    "# typeArray.append(('isLong', np.bool)) # direction (1 = long, 0 = short)\n",
    "typeArray.append(('labels', np.int)) # is winner (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffa0011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ema14_0</th>\n",
       "      <th>ema14_1</th>\n",
       "      <th>ema14_2</th>\n",
       "      <th>ema14_3</th>\n",
       "      <th>ema14_4</th>\n",
       "      <th>ema50_0</th>\n",
       "      <th>ema50_1</th>\n",
       "      <th>ema50_2</th>\n",
       "      <th>ema50_3</th>\n",
       "      <th>ema50_4</th>\n",
       "      <th>atr14_0</th>\n",
       "      <th>atr14_1</th>\n",
       "      <th>atr14_2</th>\n",
       "      <th>atr14_3</th>\n",
       "      <th>atr14_4</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2086.585693</td>\n",
       "      <td>2086.574463</td>\n",
       "      <td>2086.564453</td>\n",
       "      <td>2086.522461</td>\n",
       "      <td>2086.452881</td>\n",
       "      <td>2086.350342</td>\n",
       "      <td>2086.356201</td>\n",
       "      <td>2086.361816</td>\n",
       "      <td>2086.357422</td>\n",
       "      <td>2086.343506</td>\n",
       "      <td>0.319288</td>\n",
       "      <td>0.314339</td>\n",
       "      <td>0.291886</td>\n",
       "      <td>0.306751</td>\n",
       "      <td>0.302698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2087.169189</td>\n",
       "      <td>2087.146729</td>\n",
       "      <td>2087.093750</td>\n",
       "      <td>2087.047852</td>\n",
       "      <td>2086.974854</td>\n",
       "      <td>2086.751953</td>\n",
       "      <td>2086.761719</td>\n",
       "      <td>2086.761230</td>\n",
       "      <td>2086.760742</td>\n",
       "      <td>2086.750488</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>0.297371</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>0.272988</td>\n",
       "      <td>0.271346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2086.032715</td>\n",
       "      <td>2086.028320</td>\n",
       "      <td>2086.024658</td>\n",
       "      <td>2086.021240</td>\n",
       "      <td>2086.051758</td>\n",
       "      <td>2086.240967</td>\n",
       "      <td>2086.231445</td>\n",
       "      <td>2086.222412</td>\n",
       "      <td>2086.213623</td>\n",
       "      <td>2086.215088</td>\n",
       "      <td>0.211080</td>\n",
       "      <td>0.196003</td>\n",
       "      <td>0.217717</td>\n",
       "      <td>0.237880</td>\n",
       "      <td>0.238746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2087.002441</td>\n",
       "      <td>2087.002197</td>\n",
       "      <td>2086.968506</td>\n",
       "      <td>2086.939453</td>\n",
       "      <td>2086.914062</td>\n",
       "      <td>2086.646729</td>\n",
       "      <td>2086.660645</td>\n",
       "      <td>2086.664307</td>\n",
       "      <td>2086.667480</td>\n",
       "      <td>2086.670898</td>\n",
       "      <td>0.289215</td>\n",
       "      <td>0.286414</td>\n",
       "      <td>0.283813</td>\n",
       "      <td>0.281398</td>\n",
       "      <td>0.279155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2086.461426</td>\n",
       "      <td>2086.466553</td>\n",
       "      <td>2086.470947</td>\n",
       "      <td>2086.508057</td>\n",
       "      <td>2086.573730</td>\n",
       "      <td>2086.619629</td>\n",
       "      <td>2086.614990</td>\n",
       "      <td>2086.610596</td>\n",
       "      <td>2086.615967</td>\n",
       "      <td>2086.631104</td>\n",
       "      <td>0.191699</td>\n",
       "      <td>0.213720</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>0.202136</td>\n",
       "      <td>0.205555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33752</th>\n",
       "      <td>4180.857910</td>\n",
       "      <td>4180.843750</td>\n",
       "      <td>4180.764648</td>\n",
       "      <td>4180.762695</td>\n",
       "      <td>4180.561035</td>\n",
       "      <td>4177.078613</td>\n",
       "      <td>4177.222656</td>\n",
       "      <td>4177.341309</td>\n",
       "      <td>4177.475098</td>\n",
       "      <td>4177.544434</td>\n",
       "      <td>2.220212</td>\n",
       "      <td>2.240197</td>\n",
       "      <td>2.187326</td>\n",
       "      <td>2.120374</td>\n",
       "      <td>2.129633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33753</th>\n",
       "      <td>4170.096680</td>\n",
       "      <td>4169.783691</td>\n",
       "      <td>4169.512695</td>\n",
       "      <td>4169.210938</td>\n",
       "      <td>4169.182617</td>\n",
       "      <td>4173.228516</td>\n",
       "      <td>4173.013672</td>\n",
       "      <td>4172.807129</td>\n",
       "      <td>4172.589355</td>\n",
       "      <td>4172.448242</td>\n",
       "      <td>2.329497</td>\n",
       "      <td>2.288104</td>\n",
       "      <td>2.285382</td>\n",
       "      <td>2.247141</td>\n",
       "      <td>2.283059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33754</th>\n",
       "      <td>4173.316895</td>\n",
       "      <td>4173.274414</td>\n",
       "      <td>4173.304688</td>\n",
       "      <td>4173.264160</td>\n",
       "      <td>4173.162109</td>\n",
       "      <td>4172.644043</td>\n",
       "      <td>4172.658203</td>\n",
       "      <td>4172.691406</td>\n",
       "      <td>4172.703125</td>\n",
       "      <td>4172.695312</td>\n",
       "      <td>1.727032</td>\n",
       "      <td>1.728672</td>\n",
       "      <td>1.694481</td>\n",
       "      <td>1.662733</td>\n",
       "      <td>1.597538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33755</th>\n",
       "      <td>4169.434082</td>\n",
       "      <td>4169.109863</td>\n",
       "      <td>4168.828125</td>\n",
       "      <td>4168.684570</td>\n",
       "      <td>4168.793457</td>\n",
       "      <td>4171.307617</td>\n",
       "      <td>4171.138672</td>\n",
       "      <td>4170.976074</td>\n",
       "      <td>4170.849609</td>\n",
       "      <td>4170.796875</td>\n",
       "      <td>1.756501</td>\n",
       "      <td>1.756036</td>\n",
       "      <td>1.737748</td>\n",
       "      <td>1.738623</td>\n",
       "      <td>1.775150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33756</th>\n",
       "      <td>4159.763184</td>\n",
       "      <td>4159.794434</td>\n",
       "      <td>4159.755371</td>\n",
       "      <td>4159.788086</td>\n",
       "      <td>4159.782715</td>\n",
       "      <td>4157.833008</td>\n",
       "      <td>4157.917969</td>\n",
       "      <td>4157.979980</td>\n",
       "      <td>4158.059082</td>\n",
       "      <td>4158.125488</td>\n",
       "      <td>1.182963</td>\n",
       "      <td>1.169894</td>\n",
       "      <td>1.157759</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.119445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33757 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ema14_0      ema14_1      ema14_2      ema14_3      ema14_4  \\\n",
       "0      2086.585693  2086.574463  2086.564453  2086.522461  2086.452881   \n",
       "1      2087.169189  2087.146729  2087.093750  2087.047852  2086.974854   \n",
       "2      2086.032715  2086.028320  2086.024658  2086.021240  2086.051758   \n",
       "3      2087.002441  2087.002197  2086.968506  2086.939453  2086.914062   \n",
       "4      2086.461426  2086.466553  2086.470947  2086.508057  2086.573730   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "33752  4180.857910  4180.843750  4180.764648  4180.762695  4180.561035   \n",
       "33753  4170.096680  4169.783691  4169.512695  4169.210938  4169.182617   \n",
       "33754  4173.316895  4173.274414  4173.304688  4173.264160  4173.162109   \n",
       "33755  4169.434082  4169.109863  4168.828125  4168.684570  4168.793457   \n",
       "33756  4159.763184  4159.794434  4159.755371  4159.788086  4159.782715   \n",
       "\n",
       "           ema50_0      ema50_1      ema50_2      ema50_3      ema50_4  \\\n",
       "0      2086.350342  2086.356201  2086.361816  2086.357422  2086.343506   \n",
       "1      2086.751953  2086.761719  2086.761230  2086.760742  2086.750488   \n",
       "2      2086.240967  2086.231445  2086.222412  2086.213623  2086.215088   \n",
       "3      2086.646729  2086.660645  2086.664307  2086.667480  2086.670898   \n",
       "4      2086.619629  2086.614990  2086.610596  2086.615967  2086.631104   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "33752  4177.078613  4177.222656  4177.341309  4177.475098  4177.544434   \n",
       "33753  4173.228516  4173.013672  4172.807129  4172.589355  4172.448242   \n",
       "33754  4172.644043  4172.658203  4172.691406  4172.703125  4172.695312   \n",
       "33755  4171.307617  4171.138672  4170.976074  4170.849609  4170.796875   \n",
       "33756  4157.833008  4157.917969  4157.979980  4158.059082  4158.125488   \n",
       "\n",
       "        atr14_0   atr14_1   atr14_2   atr14_3   atr14_4  labels  \n",
       "0      0.319288  0.314339  0.291886  0.306751  0.302698       1  \n",
       "1      0.301015  0.297371  0.293987  0.272988  0.271346       0  \n",
       "2      0.211080  0.196003  0.217717  0.237880  0.238746       0  \n",
       "3      0.289215  0.286414  0.283813  0.281398  0.279155       0  \n",
       "4      0.191699  0.213720  0.198455  0.202136  0.205555       0  \n",
       "...         ...       ...       ...       ...       ...     ...  \n",
       "33752  2.220212  2.240197  2.187326  2.120374  2.129633       0  \n",
       "33753  2.329497  2.288104  2.285382  2.247141  2.283059       0  \n",
       "33754  1.727032  1.728672  1.694481  1.662733  1.597538       0  \n",
       "33755  1.756501  1.756036  1.737748  1.738623  1.775150       1  \n",
       "33756  1.182963  1.169894  1.157759  1.128633  1.119445       0  \n",
       "\n",
       "[33757 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.fromfile(trainingFileName, dtype=(typeArray)))\n",
    "#df = pd.read_csv(trainingFileName, header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6d8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervised_dataset(data, isScale, isLabelEncode):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        X.append(data[i][:-1])\n",
    "        y.append(data[i][-1])\n",
    "        \n",
    "    if (isScale):\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "    if (isLabelEncode):\n",
    "        encoder = sklearn.preprocessing.LabelEncoder()\n",
    "        encoder.fit(y)\n",
    "        y = encoder.transform(y)\n",
    "        y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf02641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.27752595 -1.2774767  -1.27749922 -1.27751992 -1.27754228 -1.28094971\n",
      " -1.28080128 -1.28067794 -1.28055969 -1.28044759 -0.37259479 -0.37654183\n",
      " -0.40046346 -0.42268338 -0.45674399] [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "\n",
    "isLabelEncode = True\n",
    "X, y = create_supervised_dataset(dataset, isScale=True, isLabelEncode=isLabelEncode)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "tfds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batchSize)\n",
    "tfds_train\n",
    "\n",
    "tfds_test = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batchSize)\n",
    "tfds_test\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756e46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57fdd61d",
   "metadata": {},
   "source": [
    "## Look at label distribution\n",
    "If the dataset is imbalanced, use `class_weights` parameter to better score the fit training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacd548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = 0\n",
    "zeros = 0\n",
    "total = 1\n",
    "\n",
    "def analyze_dataset(dataset, labels):\n",
    "    train_ones = []\n",
    "    train_zeros = []\n",
    "    for i in range(0, len(labels)):\n",
    "        if (isLabelEncode == True):\n",
    "            if(np.argmax(labels[i]) == 1):\n",
    "                train_ones.append(1)\n",
    "            if(np.argmax(labels[i]) == 0):\n",
    "                train_zeros.append(0)\n",
    "        elif (isLabelEncode == False):\n",
    "            if(y_train[i] == 1):\n",
    "                train_ones.append(1)\n",
    "            if(y_train[i]== 0):\n",
    "                train_zeros.append(0)\n",
    "\n",
    "    ones = len(train_ones)\n",
    "    zeros = len(train_zeros)\n",
    "    total = ones + zeros\n",
    "    \n",
    "    ratio = np.maximum(ones, zeros) / np.minimum(ones, zeros)\n",
    "\n",
    "    print(f'ones: {ones} zeros: {zeros}')\n",
    "    print(f'if model predicts all zeros: {zeros/total:.2%}')\n",
    "    print(f'if model predicts all ones: {ones/total:.2%}')\n",
    "\n",
    "    # fit with weights\n",
    "    weights = {0:1, 1:1}\n",
    "\n",
    "    if (zeros > ones):\n",
    "        weights = {0:1, 1:ratio}\n",
    "        print(f'ratio 0s : 1s: {ratio}')\n",
    "    else:\n",
    "        weights = {0:ratio, 1:1}\n",
    "        print(f'ratio 1s : 0s: {ratio}')\n",
    "    pyplot.bar([0, 1], [zeros, ones])\n",
    "    \n",
    "    return zeros, ones, total, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d68f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones: 5653 zeros: 16964\n",
      "if model predicts all zeros: 75.01%\n",
      "if model predicts all ones: 24.99%\n",
      "ratio 0s : 1s: 3.000884486113568\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeros, ones, total, weights = analyze_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a5d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones: 2805 zeros: 8335\n",
      "if model predicts all zeros: 74.82%\n",
      "if model predicts all ones: 25.18%\n",
      "ratio 0s : 1s: 2.971479500891266\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWHklEQVR4nO3df5Bd5X3f8fcnKODYSSzJbFQiYUseq/HgTI3JDhDbk9aWIwTuWHRqUzxJvaHqKGlpGredaaD+Qy02U5x2SsK0pqMxioWTgAmNBzWmIWuBJ9Nx+bHYGAM21gImSAW0QYLUYUws8u0f91n7ouxq76K7d6Wc92vmzn3Oc55z7vccls89Ovfce1JVSJK64YeWuwBJ0ugY+pLUIYa+JHWIoS9JHWLoS1KHrFjuAo7l9NNPr/Xr1y93GZJ0Urn//vv/rKrG5pp3Qof++vXrmZqaWu4yJOmkkuTJ+eZ5ekeSOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I65IT+Ru7xWn/FF5a7BJ2gvn3N+5e7BGlZeKQvSR1i6EtShxj6ktQhhr4kdchAoZ/kXyV5OMlDSW5K8pokG5Lck2Q6yeeSnNrGntamp9v89X3rubL1P5rkgiXaJknSPBYM/SRrgX8JjFfVTwOnAJcCnwSuraq3AIeBbW2RbcDh1n9tG0eSs9pybwO2AJ9KcspwN0eSdCyDnt5ZAfxIkhXAa4GngfcCt7b5u4GLW3trm6bN35Qkrf/mqnqpqp4ApoFzj3sLJEkDWzD0q+oA8J+BP6UX9i8A9wPPV9WRNmw/sLa11wJPtWWPtPFv6O+fY5nvS7I9yVSSqZmZmVezTZKkeQxyemcVvaP0DcBPAq+jd3pmSVTVzqoar6rxsbE5b/EoSXqVBjm98z7giaqaqarvAX8AvAtY2U73AKwDDrT2AeBMgDb/9cBz/f1zLCNJGoFBQv9PgfOTvLadm98EPALcBXywjZkAbmvtPW2aNv/OqqrWf2m7umcDsBG4dzibIUkaxIK/vVNV9yS5FfgKcAT4KrAT+AJwc5JPtL4b2iI3AJ9NMg0confFDlX1cJJb6L1hHAEur6qXh7w9kqRjGOgH16pqB7DjqO7HmePqm6r6LvChedZzNXD1ImuUJA2J38iVpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOmSQG6P/VJIH+h5/nuSjSVYnmUyyrz2vauOT5Lok00keTHJO37om2vh9SSbmf1VJ0lJYMPSr6tGqOruqzgZ+BngR+DxwBbC3qjYCe9s0wIX07n+7EdgOXA+QZDW9u2+dR++OWztm3ygkSaOx2NM7m4DHqupJYCuwu/XvBi5u7a3AjdVzN7AyyRnABcBkVR2qqsPAJLDleDdAkjS4xYb+pcBNrb2mqp5u7WeANa29Fniqb5n9rW++/ldIsj3JVJKpmZmZRZYnSTqWgUM/yanAB4DfP3peVRVQwyioqnZW1XhVjY+NjQ1jlZKkZjFH+hcCX6mqZ9v0s+20De35YOs/AJzZt9y61jdfvyRpRBYT+h/mB6d2APYAs1fgTAC39fV/pF3Fcz7wQjsNdAewOcmq9gHu5tYnSRqRFYMMSvI64OeBX+7rvga4Jck24EngktZ/O3ARME3vSp/LAKrqUJKPA/e1cVdV1aHj3gJJ0sAGCv2q+gvgDUf1PUfvap6jxxZw+Tzr2QXsWnyZkqRh8Bu5ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocMFPpJVia5Nck3k3wjyc8mWZ1kMsm+9ryqjU2S65JMJ3kwyTl965lo4/clmZj/FSVJS2HQI/3fAv6oqt4KvB34BnAFsLeqNgJ72zT0bqC+sT22A9cDJFkN7ADOA84Fdsy+UUiSRmPB0E/yeuDngBsAquovq+p5YCuwuw3bDVzc2luBG6vnbmBlkjOAC4DJqjpUVYeBSWDLELdFkrSAQY70NwAzwG8n+WqST7cbpa+pqqfbmGeANa29Fniqb/n9rW++/ldIsj3JVJKpmZmZxW2NJOmYBgn9FcA5wPVV9Q7gL/jBqRzg+zdDr2EUVFU7q2q8qsbHxsaGsUpJUjNI6O8H9lfVPW36VnpvAs+20za054Nt/gHgzL7l17W++folSSOyYOhX1TPAU0l+qnVtAh4B9gCzV+BMALe19h7gI+0qnvOBF9ppoDuAzUlWtQ9wN7c+SdKIrBhw3K8Cv5vkVOBx4DJ6bxi3JNkGPAlc0sbeDlwETAMvtrFU1aEkHwfua+OuqqpDQ9kKSdJABgr9qnoAGJ9j1qY5xhZw+Tzr2QXsWkR9kqQh8hu5ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdMlDoJ/l2kq8neSDJVOtbnWQyyb72vKr1J8l1SaaTPJjknL71TLTx+5JMzPd6kqSlsZgj/fdU1dlVNXszlSuAvVW1EdjLD26WfiGwsT22A9dD700C2AGcB5wL7Jh9o5AkjcbxnN7ZCuxu7d3AxX39N1bP3cDKduP0C4DJqjpUVYeBSWDLcby+JGmRBg39Av44yf1Jtre+Ne2G5wDPAGtaey3wVN+y+1vffP2SpBEZ9Mbo766qA0l+AphM8s3+mVVVSWoYBbU3le0Ab3zjG4exSklSM9CRflUdaM8Hgc/TOyf/bDttQ3s+2IYfAM7sW3xd65uv/+jX2llV41U1PjY2tritkSQd04Khn+R1SX5stg1sBh4C9gCzV+BMALe19h7gI+0qnvOBF9ppoDuAzUlWtQ9wN7c+SdKIDHJ6Zw3w+SSz43+vqv4oyX3ALUm2AU8Cl7TxtwMXAdPAi8BlAFV1KMnHgfvauKuq6tDQtkSStKAFQ7+qHgfePkf/c8CmOfoLuHyede0Cdi2+TEnSMPiNXEnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDBg79JKck+WqSP2zTG5Lck2Q6yeeSnNr6T2vT023++r51XNn6H01ywdC3RpJ0TIs50v814Bt9058Erq2qtwCHgW2tfxtwuPVf28aR5CzgUuBtwBbgU0lOOb7yJUmLMVDoJ1kHvB/4dJsO8F7g1jZkN3Bxa29t07T5m9r4rcDNVfVSVT1B7x665w5hGyRJAxr0SP83gX8L/FWbfgPwfFUdadP7gbWtvRZ4CqDNf6GN/37/HMt8X5LtSaaSTM3MzAy+JZKkBS0Y+kn+PnCwqu4fQT1U1c6qGq+q8bGxsVG8pCR1xooBxrwL+ECSi4DXAD8O/BawMsmKdjS/DjjQxh8AzgT2J1kBvB54rq9/Vv8ykqQRWPBIv6qurKp1VbWe3gexd1bVLwB3AR9swyaA21p7T5umzb+zqqr1X9qu7tkAbATuHdqWSJIWNMiR/nx+Hbg5ySeArwI3tP4bgM8mmQYO0XujoKoeTnIL8AhwBLi8ql4+jteXJC3SokK/qr4EfKm1H2eOq2+q6rvAh+ZZ/mrg6sUWKUkaDr+RK0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHXIIDdGf02Se5N8LcnDSf5D69+Q5J4k00k+l+TU1n9am55u89f3revK1v9okguWbKskSXMa5Ej/JeC9VfV24GxgS5LzgU8C11bVW4DDwLY2fhtwuPVf28aR5Cx6t058G7AF+FSSU4a4LZKkBQxyY/Sqqu+0yR9ujwLeC9za+ncDF7f21jZNm78pSVr/zVX1UlU9AUwzx+0WJUlLZ6Bz+klOSfIAcBCYBB4Dnq+qI23IfmBta68FngJo818A3tDfP8cy/a+1PclUkqmZmZlFb5AkaX4DhX5VvVxVZwPr6B2dv3WpCqqqnVU1XlXjY2NjS/UyktRJi7p6p6qeB+4CfhZYmWRFm7UOONDaB4AzAdr81wPP9ffPsYwkaQQGuXpnLMnK1v4R4OeBb9AL/w+2YRPAba29p03T5t9ZVdX6L21X92wANgL3Dmk7JEkDWLHwEM4AdrcrbX4IuKWq/jDJI8DNST4BfBW4oY2/AfhskmngEL0rdqiqh5PcAjwCHAEur6qXh7s5kqRjWTD0q+pB4B1z9D/OHFffVNV3gQ/Ns66rgasXX6b0N9P6K76w3CXoBPXta96/JOv1G7mS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShwxyu8Qzk9yV5JEkDyf5tda/Oslkkn3teVXrT5LrkkwneTDJOX3rmmjj9yWZmO81JUlLY5Aj/SPAv6mqs4DzgcuTnAVcAeytqo3A3jYNcCG9+99uBLYD10PvTQLYAZxH745bO2bfKCRJo7Fg6FfV01X1ldb+f/Ruir4W2ArsbsN2Axe39lbgxuq5G1iZ5AzgAmCyqg5V1WFgEtgyzI2RJB3bos7pJ1lP73659wBrqurpNusZYE1rrwWe6ltsf+ubr//o19ieZCrJ1MzMzGLKkyQtYODQT/KjwP8APlpVf94/r6oKqGEUVFU7q2q8qsbHxsaGsUpJUjNQ6Cf5YXqB/7tV9Qet+9l22ob2fLD1HwDO7Ft8Xeubr1+SNCKDXL0T4AbgG1X1X/pm7QFmr8CZAG7r6/9Iu4rnfOCFdhroDmBzklXtA9zNrU+SNCIrBhjzLuAfA19P8kDr+3fANcAtSbYBTwKXtHm3AxcB08CLwGUAVXUoyceB+9q4q6rq0DA2QpI0mAVDv6r+N5B5Zm+aY3wBl8+zrl3ArsUUKEkaHr+RK0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHXIILdL3JXkYJKH+vpWJ5lMsq89r2r9SXJdkukkDyY5p2+ZiTZ+X5KJuV5LkrS0BjnS/wyw5ai+K4C9VbUR2NumAS4ENrbHduB66L1JADuA84BzgR2zbxSSpNFZMPSr6k+Ao+9luxXY3dq7gYv7+m+snruBlUnOAC4AJqvqUFUdBib5628kkqQl9mrP6a+pqqdb+xlgTWuvBZ7qG7e/9c3X/9ck2Z5kKsnUzMzMqyxPkjSX4/4gt90IvYZQy+z6dlbVeFWNj42NDWu1kiRefeg/207b0J4Ptv4DwJl949a1vvn6JUkj9GpDfw8wewXOBHBbX/9H2lU85wMvtNNAdwCbk6xqH+Bubn2SpBFasdCAJDcBfw84Pcl+elfhXAPckmQb8CRwSRt+O3ARMA28CFwGUFWHknwcuK+Nu6qqjv5wWJK0xBYM/ar68DyzNs0xtoDL51nPLmDXoqqTJA2V38iVpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOmTkoZ9kS5JHk0wnuWLUry9JXTbS0E9yCvDfgAuBs4APJzlrlDVIUpeN+kj/XGC6qh6vqr8Ebga2jrgGSeqsBe+RO2Rrgaf6pvcD5/UPSLId2N4mv5Pk0RHV9mqdDvzZchcxAOvsk08OZTXu0+E6WeqEEdR6nH+jb5pvxqhDf0FVtRPYudx1DCrJVFWNL3cdC7HO4TtZarXO4TuZaj3aqE/vHADO7Jte1/okSSMw6tC/D9iYZEOSU4FLgT0jrkGSOmukp3eq6kiSfwHcAZwC7Kqqh0dZwxI4WU5FWefwnSy1WufwnUy1vkKqarlrkCSNiN/IlaQOMfQlqUMM/QEkWZ1kMsm+9rxqjjFnJ/k/SR5O8mCSf9Q37zNJnkjyQHucPeT6jvnTFklOS/K5Nv+eJOv75l3Z+h9NcsEw63oVdf7rJI+0/bc3yZv65r3ct/+W9MP/Aer8pSQzffX80755E+3vZF+SiWWu89q+Gr+V5Pm+eaPcn7uSHEzy0Dzzk+S6th0PJjmnb94o9+dCdf5Cq+/rSb6c5O19877d+h9IMrWUdR63qvKxwAP4DeCK1r4C+OQcY/42sLG1fxJ4GljZpj8DfHCJajsFeAx4M3Aq8DXgrKPG/HPgv7f2pcDnWvusNv40YENbzynLWOd7gNe29j+brbNNf2dE/60HqfOXgP86x7Krgcfb86rWXrVcdR41/lfpXTgx0v3ZXuvngHOAh+aZfxHwv4AA5wP3jHp/DljnO2dfn95PydzTN+/bwOmj2qfH8/BIfzBbgd2tvRu4+OgBVfWtqtrX2v8XOAiMjaC2QX7aor/+W4FNSdL6b66ql6rqCWC6rW9Z6qyqu6rqxTZ5N73vcYza8fxUyAXAZFUdqqrDwCSw5QSp88PATUtUyzFV1Z8Ah44xZCtwY/XcDaxMcgaj3Z8L1llVX251wPL9fR43Q38wa6rq6dZ+BlhzrMFJzqV39PVYX/fV7Z+G1yY5bYi1zfXTFmvnG1NVR4AXgDcMuOwo6+y3jd7R36zXJJlKcneSi5egvlmD1vkP23/PW5PMfuHwhNyf7TTZBuDOvu5R7c9BzLcto9yfi3X032cBf5zk/vZTMiesE+5nGJZLki8Cf2uOWR/rn6iqSjLvda7tCOWzwERV/VXrvpLem8Wp9K7v/XXgqmHU/TdRkl8ExoG/29f9pqo6kOTNwJ1Jvl5Vj829hiX3P4GbquqlJL9M719R712mWgZxKXBrVb3c13ci7c+TSpL30Av9d/d1v7vtz58AJpN8s/3L4YTjkX5TVe+rqp+e43Eb8GwL89lQPzjXOpL8OPAF4GPtn6mz6366/dP1JeC3Ge4plEF+2uL7Y5KsAF4PPDfgsqOskyTvo/dG+4G2vwCoqgPt+XHgS8A7lqvOqnqur7ZPAz8z6LKjrLPPpRx1ameE+3MQ823LCfezLUn+Dr3/5lur6rnZ/r79eRD4PEt3mvT4LfeHCifDA/hPvPKD3N+YY8ypwF7go3PMO6M9B/hN4Joh1raC3gdcG/jBB3pvO2rM5bzyg9xbWvttvPKD3MdZug9yB6nzHfROiW08qn8VcFprnw7s4xgfWo6gzjP62v8AuLu1VwNPtHpXtfbq5aqzjXsrvQ8Zsxz7s+811zP/B6Tv55Uf5N476v05YJ1vpPe51zuP6n8d8GN97S8DW5ayzuPaxuUu4GR40Dv/vbf9z/HF2T88eqcgPt3avwh8D3ig73F2m3cn8HXgIeB3gB8dcn0XAd9qgfmx1ncVvaNlgNcAv9/+YO8F3ty37Mfaco8CFy7xflyozi8Cz/btvz2t/51t/32tPW9b5jr/I/Bwq+cu4K19y/6Ttp+ngcuWs842/e856iBjGfbnTfSuZvsevfPy24BfAX6lzQ+9mys91uoZX6b9uVCdnwYO9/19TrX+N7d9+bX2d/GxpazzeB/+DIMkdYjn9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrk/wOQRu7v7cbzmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeros, ones, total, weights = analyze_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f3f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones: 2805 zeros: 8335\n"
     ]
    }
   ],
   "source": [
    "print(f'ones: {ones} zeros: {zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107f4dc",
   "metadata": {},
   "source": [
    "## Define Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44fe7913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_model_accuracy(model):\n",
    "    correct = 0\n",
    "    num_predictions = 50\n",
    "    for i in range(0, num_predictions):\n",
    "        in_x = X_test[i].reshape(1, X_train.shape[1])\n",
    "        lbl = y_test[i]\n",
    "        yhat = model.predict(in_x)\n",
    "        if (isLabelEncode):\n",
    "            pred = np.argmax(yhat)\n",
    "            actual = np.argmax(y_test[i])\n",
    "            print(f'pred: [{yhat[0][0]:.3} {yhat[0][1]:.3}] actual: {y_test[i]} {\"|||\":10} pred: {pred} actual: {actual}')\n",
    "            \n",
    "            if (pred == actual):\n",
    "                correct += 1\n",
    "        else:\n",
    "            print(f'pred: {yhat[0]:.4} actual: {y_test[i]}')\n",
    "            \n",
    "    print(f'correct: {correct / num_predictions:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44760fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    yhat = model.predict(X_test)\n",
    "    # evaluate the ROC AUC of the predictions\n",
    "    score = sklearn.metrics.roc_auc_score(y_test, yhat)\n",
    "    print(f'ROC AUC: {score:.3%}')\n",
    "    test_model_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b373f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network model\n",
    "def simple_model(x_input, outClasses):\n",
    "    # define model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # define first hidden layer and visible layer\n",
    "    model.add(tf.keras.layers.Dense(10, input_dim=x_input.shape[1], activation='relu',  kernel_initializer='he_uniform'))\n",
    "    # define output layer\n",
    "    #model.add(tf.keras.layers.Dense(outClasses, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(outClasses, activation='softmax'))\n",
    "    # define loss and optimizer\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='sgd')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51737c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209696ec",
   "metadata": {},
   "source": [
    "### Test vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d91e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1414/1414 - 4s - loss: 0.5784 - accuracy: 0.7462 - val_loss: 0.5604 - val_accuracy: 0.7525\n",
      "Epoch 2/10\n",
      "1414/1414 - 3s - loss: 0.5603 - accuracy: 0.7477 - val_loss: 0.5576 - val_accuracy: 0.7525\n",
      "Epoch 3/10\n",
      "1414/1414 - 3s - loss: 0.5590 - accuracy: 0.7478 - val_loss: 0.5565 - val_accuracy: 0.7526\n",
      "Epoch 4/10\n",
      "1414/1414 - 3s - loss: 0.5585 - accuracy: 0.7478 - val_loss: 0.5560 - val_accuracy: 0.7526\n",
      "Epoch 5/10\n",
      "1414/1414 - 3s - loss: 0.5582 - accuracy: 0.7477 - val_loss: 0.5557 - val_accuracy: 0.7526\n",
      "Epoch 6/10\n",
      "1414/1414 - 3s - loss: 0.5580 - accuracy: 0.7478 - val_loss: 0.5555 - val_accuracy: 0.7526\n",
      "Epoch 7/10\n",
      "1414/1414 - 3s - loss: 0.5579 - accuracy: 0.7477 - val_loss: 0.5553 - val_accuracy: 0.7526\n",
      "Epoch 8/10\n",
      "1414/1414 - 3s - loss: 0.5578 - accuracy: 0.7477 - val_loss: 0.5552 - val_accuracy: 0.7527\n",
      "Epoch 9/10\n",
      "1414/1414 - 3s - loss: 0.5577 - accuracy: 0.7476 - val_loss: 0.5551 - val_accuracy: 0.7527\n",
      "Epoch 10/10\n",
      "1414/1414 - 3s - loss: 0.5576 - accuracy: 0.7476 - val_loss: 0.5551 - val_accuracy: 0.7527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e2b6ccf400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simple_model(X_train, num_out_classes)\n",
    "model.fit(tfds_train, validation_data=tfds_test, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f1dea32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 56.736%\n",
      "pred: [0.818 0.182] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.878 0.122] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.892 0.108] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.93 0.0699] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.926 0.0744] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.928 0.0722] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.841 0.159] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.931 0.069] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.867 0.133] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.843 0.157] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.934 0.0655] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.92 0.0798] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.791 0.209] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.869 0.131] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.949 0.051] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.854 0.146] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.891 0.109] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.844 0.156] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.839 0.161] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.792 0.208] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.864 0.136] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.925 0.0746] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.804 0.196] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.849 0.151] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.932 0.0676] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.94 0.06] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.9 0.1] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.925 0.0745] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.851 0.149] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.913 0.0872] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.918 0.0822] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.939 0.0613] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.951 0.0491] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.928 0.0724] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.938 0.062] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.884 0.116] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.949 0.0511] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.945 0.0547] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.935 0.0654] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.789 0.211] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.899 0.101] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.837 0.163] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.901 0.0994] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.813 0.187] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.881 0.119] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.952 0.0484] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.925 0.0752] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.919 0.0806] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.935 0.0653] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.853 0.147] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "correct: 66.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76c3fc",
   "metadata": {},
   "source": [
    "74% correct!!! At first glance, this looks fantastic.  However, if the training dataset is used for comparison, a model which predicts all zeros must do better than 71.95%.  The numbers are slightly different for the test dataset but the idea is the same.  Due to the stochastic nature of deep learning, this approximately 2% advantage should be met with significant skepticism.  Given the fact that the dataset is imbalanced, the `class_weight` parameter should be utilized at a minimum.  SMOTE or other sampling techniques would likely be a more robust way to evaluate this model.\n",
    "\n",
    "In classification problems, accuracy on tells part of the story (often a less important part).  ROC AUC and F1 score are often a much better indicator of the ability of the model.  This super simple model only achieves a ROC AUC of 55% which is nothing stellar and is not likely to have reliable prediction skill.\n",
    "\n",
    "The final indication that this model is essentially garbage is the predictions are always 0.  There could be several reasons for this:\n",
    " - Massive overfitting (most likely in this case)\n",
    " - Too aggressive of a learning rate\n",
    " - Too complex of a model (model just memorizes the dataset)\n",
    " - Imbalanced dataset\n",
    " \n",
    "This model's predictions vary only a slight amount and always are heavily weighted to predict zero.  The fact that the prediction probabilities do change means that the model is sound, but is just overall terrible.  This is to be expected with a single Dense layer with only 10 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e1de1",
   "metadata": {},
   "source": [
    "### Test properly class weighted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "851da59f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jason\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n",
      "1414/1414 - 4s - loss: 1.0426 - accuracy: 0.5597 - val_loss: 0.6983 - val_accuracy: 0.5350\n",
      "Epoch 2/10\n",
      "1414/1414 - 3s - loss: 1.0373 - accuracy: 0.5613 - val_loss: 0.7005 - val_accuracy: 0.5289\n",
      "Epoch 3/10\n",
      "1414/1414 - 4s - loss: 1.0365 - accuracy: 0.5538 - val_loss: 0.7012 - val_accuracy: 0.5250\n",
      "Epoch 4/10\n",
      "1414/1414 - 3s - loss: 1.0360 - accuracy: 0.5506 - val_loss: 0.7016 - val_accuracy: 0.5232\n",
      "Epoch 5/10\n",
      "1414/1414 - 4s - loss: 1.0357 - accuracy: 0.5490 - val_loss: 0.7016 - val_accuracy: 0.5229\n",
      "Epoch 6/10\n",
      "1414/1414 - 3s - loss: 1.0355 - accuracy: 0.5477 - val_loss: 0.7016 - val_accuracy: 0.5224\n",
      "Epoch 7/10\n",
      "1414/1414 - 3s - loss: 1.0353 - accuracy: 0.5473 - val_loss: 0.7014 - val_accuracy: 0.5226\n",
      "Epoch 8/10\n",
      "1414/1414 - 3s - loss: 1.0352 - accuracy: 0.5471 - val_loss: 0.7012 - val_accuracy: 0.5231\n",
      "Epoch 9/10\n",
      "1414/1414 - 3s - loss: 1.0351 - accuracy: 0.5469 - val_loss: 0.7011 - val_accuracy: 0.5228\n",
      "Epoch 10/10\n",
      "1414/1414 - 3s - loss: 1.0350 - accuracy: 0.5473 - val_loss: 0.7011 - val_accuracy: 0.5226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e2e32afcd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simple_model(X_train, num_out_classes)\n",
    "model.fit(tfds_train, validation_data=tfds_test, epochs=10, verbose=2, class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c603c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 57.192%\n",
      "pred: [0.336 0.664] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.441 0.559] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.444 0.556] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.603 0.397] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.573 0.427] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.586 0.414] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.356 0.644] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.593 0.407] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.448 0.552] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.406 0.594] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.581 0.419] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.541 0.459] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.336 0.664] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.44 0.56] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.665 0.335] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.325 0.675] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.41 0.59] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.344 0.656] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.38 0.62] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.303 0.697] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.354 0.646] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.502 0.498] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.377 0.623] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.381 0.619] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.615 0.385] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.615 0.385] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.495 0.505] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.56 0.44] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.315 0.685] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.468 0.532] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.536 0.464] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.641 0.359] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.687 0.313] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.569 0.431] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.636 0.364] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.436 0.564] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.676 0.324] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.645 0.355] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.562 0.438] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.286 0.714] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.493 0.507] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.336 0.664] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.513 0.487] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.341 0.659] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.461 0.539] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.642 0.358] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.588 0.412] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.565 0.435] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.605 0.395] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.346 0.654] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "correct: 58.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8155f5",
   "metadata": {},
   "source": [
    "This model with adjusted class weights gives a much more accurate representation of this model's true abilities.  When digging into the predictions, they do vary between predicting each of the 2 classes (0 and 1 - loser/winner).  however, the model's confidence is not great.  If I were to use a model in actual trading, I would want the model to be much, much more certain of its predicction 90% or better.  That would correspond to [0.9 0.1] for a zero (predict a loser, so don't trade) or [0.1 0.9] for a one (predicting a winner, take the trade).\n",
    "\n",
    "The ROC AUC is only 55.6% which is still terrible.  I would want something well over 80% before I even considered forward testing it on a demo account.  The accuracy of 50% is much more representative of this model's true ability.  It has no skill due to any one or more of the following:\n",
    "\n",
    " - The features do not possess any predictive information (most likely the case).\n",
    " - The model is not of sufficient complexity to extract predictive relationships in the data (also very likely).\n",
    " - Class weighting was not sufficient to overcome the dataset imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925655e",
   "metadata": {},
   "source": [
    "# Try more advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3d7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_deeper(x_input, outClasses):\n",
    "    # define model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # define first hidden layer and visible layer\n",
    "    model.add(tf.keras.layers.Dense(50, input_dim=x_input.shape[1], activation='relu',  kernel_initializer='he_uniform'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu',  kernel_initializer='he_uniform'))\n",
    "    # define output layer\n",
    "    #model.add(tf.keras.layers.Dense(outClasses, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(outClasses, activation='softmax'))\n",
    "    # define loss and optimizer\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='sgd')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bc41d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(x_input, outClasses):\n",
    "    # let's use the functional api to build this one\n",
    "    visible = tf.keras.layers.Input(shape=(x_input.shape[1]))\n",
    "    \n",
    "    #CNN requires 3D input in the shape [samples, time_steps, features]\n",
    "    print(f'time_steps: {time_steps} featuers: {features}')\n",
    "    reshape = tf.keras.layers.Reshape(target_shape=(time_steps,features))(visible)\n",
    "    \n",
    "    cnn = tf.keras.layers.Conv1D(32, kernel_size=2, strides=1, activation=tf.keras.activations.relu, padding='same')(reshape)\n",
    "    cnn = tf.keras.layers.Conv1D(32, kernel_size=2, strides=1, activation=tf.keras.activations.relu, padding='same')(cnn)\n",
    "    pool = tf.keras.layers.MaxPooling1D()(cnn)\n",
    "    flat = tf.keras.layers.Flatten()(pool)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(outClasses, activation=tf.keras.activations.sigmoid)(flat)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=visible, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy, optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2d2a835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22617, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22b51bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps: 5 featuers: 3\n"
     ]
    }
   ],
   "source": [
    "model = CNN(X_train, num_out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed206a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 3)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 5, 32)             224       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 354\n",
      "Trainable params: 354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fc79638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13470eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw prediction: [0.61355406 0.5281971 ] predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "# test a prediction to verify model design\n",
    "x_input = X_test[0]\n",
    "x_input = x_input.reshape(1,X_test.shape[1])\n",
    "yhat = model.predict(x_input)\n",
    "print(f'raw prediction: {yhat[0]} predicted label: {np.argmax(yhat[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78a66d3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1414/1414 - 4s - loss: 0.5817 - accuracy: 0.7427 - val_loss: 0.5601 - val_accuracy: 0.7526\n",
      "Epoch 2/10\n",
      "1414/1414 - 4s - loss: 0.5607 - accuracy: 0.7476 - val_loss: 0.5558 - val_accuracy: 0.7526\n",
      "Epoch 3/10\n",
      "1414/1414 - 4s - loss: 0.5585 - accuracy: 0.7477 - val_loss: 0.5547 - val_accuracy: 0.7526\n",
      "Epoch 4/10\n",
      "1414/1414 - 4s - loss: 0.5579 - accuracy: 0.7477 - val_loss: 0.5543 - val_accuracy: 0.7526\n",
      "Epoch 5/10\n",
      "1414/1414 - 4s - loss: 0.5576 - accuracy: 0.7478 - val_loss: 0.5542 - val_accuracy: 0.7526\n",
      "Epoch 6/10\n",
      "1414/1414 - 4s - loss: 0.5575 - accuracy: 0.7478 - val_loss: 0.5542 - val_accuracy: 0.7526\n",
      "Epoch 7/10\n",
      "1414/1414 - 4s - loss: 0.5574 - accuracy: 0.7478 - val_loss: 0.5541 - val_accuracy: 0.7526\n",
      "Epoch 8/10\n",
      "1414/1414 - 4s - loss: 0.5573 - accuracy: 0.7478 - val_loss: 0.5541 - val_accuracy: 0.7526\n",
      "Epoch 9/10\n",
      "1414/1414 - 4s - loss: 0.5572 - accuracy: 0.7478 - val_loss: 0.5541 - val_accuracy: 0.7526\n",
      "Epoch 10/10\n",
      "1414/1414 - 4s - loss: 0.5572 - accuracy: 0.7478 - val_loss: 0.5541 - val_accuracy: 0.7526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e2cbaf9520>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tfds_train, validation_data=tfds_test, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc6b41b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 57.065%\n",
      "pred: [0.644 0.35] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.751 0.253] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.754 0.248] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.779 0.222] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.786 0.21] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.782 0.216] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.694 0.298] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.785 0.206] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.73 0.275] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.72 0.288] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.792 0.212] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.77 0.22] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.667 0.332] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.72 0.273] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.802 0.187] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.7 0.317] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.736 0.27] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.693 0.299] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.714 0.286] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.683 0.322] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.739 0.269] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.768 0.232] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.681 0.326] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.704 0.296] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.793 0.2] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.795 0.196] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.761 0.251] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.782 0.214] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.725 0.282] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.757 0.244] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.776 0.233] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.789 0.196] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.806 0.183] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.782 0.211] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.797 0.208] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.753 0.252] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.799 0.183] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.795 0.2] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.779 0.218] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.68 0.327] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.762 0.249] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.691 0.321] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.762 0.236] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.673 0.332] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.735 0.266] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.808 0.193] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.78 0.208] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.775 0.222] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.785 0.2] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.702 0.317] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "correct: 66.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e513dee",
   "metadata": {},
   "source": [
    "Even with a significantly more advanced model architecture, the non class weighted model performs virtually identical to the extremely simple single Dense layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dd16bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps: 5 featuers: 3\n",
      "Epoch 1/10\n",
      "1414/1414 - 4s - loss: 1.0436 - accuracy: 0.6044 - val_loss: 0.6977 - val_accuracy: 0.5774\n",
      "Epoch 2/10\n",
      "1414/1414 - 4s - loss: 1.0394 - accuracy: 0.5929 - val_loss: 0.6971 - val_accuracy: 0.5608\n",
      "Epoch 3/10\n",
      "1414/1414 - 4s - loss: 1.0377 - accuracy: 0.5798 - val_loss: 0.6975 - val_accuracy: 0.5502\n",
      "Epoch 4/10\n",
      "1414/1414 - 4s - loss: 1.0367 - accuracy: 0.5719 - val_loss: 0.6979 - val_accuracy: 0.5442\n",
      "Epoch 5/10\n",
      "1414/1414 - 4s - loss: 1.0361 - accuracy: 0.5670 - val_loss: 0.6983 - val_accuracy: 0.5416\n",
      "Epoch 6/10\n",
      "1414/1414 - 4s - loss: 1.0357 - accuracy: 0.5627 - val_loss: 0.6987 - val_accuracy: 0.5404\n",
      "Epoch 7/10\n",
      "1414/1414 - 4s - loss: 1.0355 - accuracy: 0.5605 - val_loss: 0.6986 - val_accuracy: 0.5393\n",
      "Epoch 8/10\n",
      "1414/1414 - 4s - loss: 1.0353 - accuracy: 0.5587 - val_loss: 0.6987 - val_accuracy: 0.5380\n",
      "Epoch 9/10\n",
      "1414/1414 - 4s - loss: 1.0351 - accuracy: 0.5581 - val_loss: 0.6987 - val_accuracy: 0.5373\n",
      "Epoch 10/10\n",
      "1414/1414 - 4s - loss: 1.0350 - accuracy: 0.5572 - val_loss: 0.6986 - val_accuracy: 0.5363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e309a60c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(X_train, num_out_classes)\n",
    "model.fit(tfds_train, validation_data=tfds_test, epochs=10, verbose=2, class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd4bf82e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 57.176%\n",
      "pred: [0.379 0.628] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.489 0.509] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.491 0.503] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.541 0.458] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.546 0.453] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.536 0.46] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.431 0.565] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.553 0.445] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.469 0.533] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.444 0.555] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.545 0.457] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.535 0.464] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.402 0.59] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.466 0.528] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.584 0.41] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.419 0.586] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.469 0.536] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.422 0.573] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.438 0.566] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.395 0.602] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.45 0.545] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.512 0.493] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.417 0.576] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.449 0.552] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.561 0.439] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.565 0.433] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.494 0.509] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.54 0.459] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.423 0.566] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.498 0.501] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.518 0.486] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.574 0.424] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.59 0.404] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.544 0.453] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.56 0.444] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.486 0.513] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.593 0.407] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.559 0.442] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.531 0.472] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.384 0.617] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.494 0.507] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.413 0.591] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.505 0.493] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.416 0.578] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.481 0.519] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.579 0.429] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.55 0.446] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.528 0.467] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.562 0.438] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.417 0.587] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "correct: 58.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b19669",
   "metadata": {},
   "source": [
    "The accuracy of this CNN-based model is fairly noticeable improvement over the very simple model with a 8% improvement.  However, the ROC AUC is virtually identical which means this model is essentially no better with the quality of its predictions.  If we carefully analyze the `take trade (1)` versus `don't take trade (0)`, there are quite a significant false negatives.  The high ratio of false negatives combined with the low confidence of the predicted label could mean a few things:\n",
    "\n",
    " - This model need more training.  Even with 50 epochs, the model simply became overfitted with no improvement in skill.\n",
    " - The features do not have strong predictive information.  This is looking much more of a certainty now.\n",
    " \n",
    "Let's try other architectures to see if there is any salvaging these indicator based inputs\n",
    " - Encoder decoder\n",
    " - Recurrent Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be466f2",
   "metadata": {},
   "source": [
    "## Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0eeeedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder(x_input, outClasses):\n",
    "    # let's use the functional api to build this one\n",
    "    visible = tf.keras.layers.Input(shape=(x_input.shape[1]))    \n",
    "    reshape = tf.keras.layers.Reshape(target_shape=(time_steps,features))(visible)\n",
    "    \n",
    "    enc = tf.compat.v1.keras.layers.LSTM(20, activation='relu')(reshape)\n",
    "        \n",
    "    bottleneck = tf.keras.layers.RepeatVector(outClasses)(enc)\n",
    "    dec = tf.compat.v1.keras.layers.LSTM(20, activation='relu', return_sequences=True)(bottleneck)\n",
    "    \n",
    "    dec  = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(time_steps, activation='relu'))(dec)\n",
    "    dec = tf.keras.layers.Flatten()(dec)\n",
    "    output = tf.keras.layers.Dense(outClasses, activation='softmax')(dec)    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=visible, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2da5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoder_decoder(X_train, num_out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ec0f37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 5, 3)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20)                1920      \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 2, 20)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 2, 20)             3280      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 2, 5)              105       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 5,327\n",
      "Trainable params: 5,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db0122c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8f4be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw prediction: [0.50301874 0.49698123] predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "# test a prediction to verify model design\n",
    "x_input = X_test[0]\n",
    "x_input = x_input.reshape(1,X_test.shape[1])\n",
    "yhat = model.predict(x_input)\n",
    "print(f'raw prediction: {yhat[0]} predicted label: {np.argmax(yhat[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab8f1216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1414/1414 - 78s - loss: 1.0502 - accuracy: 0.7478 - val_loss: 0.6909 - val_accuracy: 0.7528\n",
      "Epoch 2/10\n",
      "1414/1414 - 72s - loss: 1.0501 - accuracy: 0.7478 - val_loss: 0.6908 - val_accuracy: 0.7527\n",
      "Epoch 3/10\n",
      "1414/1414 - 72s - loss: 1.0501 - accuracy: 0.7478 - val_loss: 0.6908 - val_accuracy: 0.7526\n",
      "Epoch 4/10\n",
      "1414/1414 - 73s - loss: 1.0501 - accuracy: 0.7474 - val_loss: 0.6908 - val_accuracy: 0.7522\n",
      "Epoch 5/10\n",
      "1414/1414 - 72s - loss: 1.0500 - accuracy: 0.7467 - val_loss: 0.6907 - val_accuracy: 0.7517\n",
      "Epoch 6/10\n",
      "1414/1414 - 72s - loss: 1.0500 - accuracy: 0.7455 - val_loss: 0.6907 - val_accuracy: 0.7466\n",
      "Epoch 7/10\n",
      "1414/1414 - 73s - loss: 1.0500 - accuracy: 0.7388 - val_loss: 0.6907 - val_accuracy: 0.7357\n",
      "Epoch 8/10\n",
      "1414/1414 - 73s - loss: 1.0500 - accuracy: 0.7189 - val_loss: 0.6906 - val_accuracy: 0.7032\n",
      "Epoch 9/10\n",
      "1414/1414 - 72s - loss: 1.0499 - accuracy: 0.6772 - val_loss: 0.6906 - val_accuracy: 0.6633\n",
      "Epoch 10/10\n",
      "1414/1414 - 73s - loss: 1.0499 - accuracy: 0.6486 - val_loss: 0.6905 - val_accuracy: 0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3482f3610>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tfds_train, validation_data=tfds_test, epochs=10, verbose=2, class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acc853f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 52.518%\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.513 0.487] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.512 0.488] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.516 0.484] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.504 0.496] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.514 0.486] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.508 0.492] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.509 0.491] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.501 0.499] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.502 0.498] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.5 0.5] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.511 0.489] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.517 0.483] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.502 0.498] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.5 0.5] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.516 0.484] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.516 0.484] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.516 0.484] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.514 0.486] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.51 0.49] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.509 0.491] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.514 0.486] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.514 0.486] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.512 0.488] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.503 0.497] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.501 0.499] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.513 0.487] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.5 0.5] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.503 0.497] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.5 0.5] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.5 0.5] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.511 0.489] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.505 0.495] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.51 0.49] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.501 0.499] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "correct: 56.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51bb5ba",
   "metadata": {},
   "source": [
    "This model architecture took significantly more system resources to train.  After 10 epochs of traininig, the validation accuracy was still climbing but the loss had remained constant.  This accuracy was still below 50% which leads me to believe that the model was not actually learning but moving towards predicting only on class.  When analyzing the `evaluate_model`, the confidence of the predictions is very close to a coin flip despite the model predicting both classes.  Again, the ROC AUC was 54% which is a terrible score for this model.\n",
    "\n",
    "After a further 10 epochs, the model reached a validation accuracy over 50%, 52.97%.  However, when evaluating the model and the test dataset, which it had not seen, the accuracy remained underwhelming at 56%.  Still, the ROC AUC remained well below an acceptable level with a mere 54.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ac562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_lstm(x_input, outClasses):\n",
    "    visible = tf.keras.layers.Input(shape=(x_input.shape[1]))    \n",
    "    reshape = tf.keras.layers.Reshape(target_shape=(time_steps,features))(visible)    \n",
    "    \n",
    "    rnn = tf.keras.layers.LSTM(4, activation='relu', kernel_constraint=tf.keras.constraints.max_norm(3), return_sequences=True)(reshape)\n",
    "    rnn = tf.keras.layers.LSTM(4, activation='relu', kernel_constraint=tf.keras.constraints.max_norm(2))(rnn)\n",
    "    #rnn = Flatten()(rnn)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(outClasses, activation='softmax')(rnn)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=visible, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "237b5e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = stacked_lstm(X_train, num_out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86de602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 3)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 5, 4)              128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4)                 144       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 282\n",
      "Trainable params: 282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9442173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6493627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw prediction: [0.4997 0.5003] predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "# test a prediction to verify model design\n",
    "x_input = X_test[0]\n",
    "x_input = x_input.reshape(1,X_test.shape[1])\n",
    "yhat = model.predict(x_input)\n",
    "print(f'raw prediction: [{yhat[0][0]:.4} {yhat[0][1]:.4}] predicted label: {np.argmax(yhat[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7711557a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jason\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n",
      "1414/1414 - 40s - loss: 1.0342 - accuracy: 0.3003 - val_loss: 0.6992 - val_accuracy: 0.3229\n",
      "Epoch 2/10\n",
      "1414/1414 - 40s - loss: 1.0341 - accuracy: 0.3439 - val_loss: 0.6988 - val_accuracy: 0.3689\n",
      "Epoch 3/10\n",
      "1414/1414 - 40s - loss: 1.0340 - accuracy: 0.4021 - val_loss: 0.6985 - val_accuracy: 0.4449\n",
      "Epoch 4/10\n",
      "1414/1414 - 39s - loss: 1.0339 - accuracy: 0.4930 - val_loss: 0.6982 - val_accuracy: 0.5252\n",
      "Epoch 5/10\n",
      "1414/1414 - 39s - loss: 1.0339 - accuracy: 0.5310 - val_loss: 0.6979 - val_accuracy: 0.5342\n",
      "Epoch 6/10\n",
      "1414/1414 - 41s - loss: 1.0338 - accuracy: 0.5382 - val_loss: 0.6977 - val_accuracy: 0.5401\n",
      "Epoch 7/10\n",
      "1414/1414 - 41s - loss: 1.0338 - accuracy: 0.5440 - val_loss: 0.6975 - val_accuracy: 0.5453\n",
      "Epoch 8/10\n",
      "1414/1414 - 39s - loss: 1.0337 - accuracy: 0.5478 - val_loss: 0.6974 - val_accuracy: 0.5499\n",
      "Epoch 9/10\n",
      "1414/1414 - 41s - loss: 1.0337 - accuracy: 0.5522 - val_loss: 0.6972 - val_accuracy: 0.5531\n",
      "Epoch 10/10\n",
      "1414/1414 - 39s - loss: 1.0336 - accuracy: 0.5566 - val_loss: 0.6971 - val_accuracy: 0.5570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144c8e60790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tfds_train, validation_data=tfds_test, epochs=10, verbose=2, class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56dfd0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 53.720%\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.468 0.532] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.48 0.52] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.458 0.542] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.469 0.531] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.505 0.495] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.47 0.53] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.494 0.506] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.505 0.495] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.499 0.501] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.498 0.502] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.505 0.495] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.499 0.501] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.504 0.496] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.501 0.499] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.428 0.572] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.464 0.536] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.479 0.521] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.501 0.499] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.457 0.543] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.504 0.496] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.498 0.502] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.504 0.496] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.494 0.506] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.465 0.535] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.493 0.507] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.46 0.54] actual: [1. 0.] |||        pred: 1 actual: 0\n",
      "pred: [0.466 0.534] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.505 0.495] actual: [0. 1.] |||        pred: 0 actual: 1\n",
      "pred: [0.467 0.533] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "pred: [0.439 0.561] actual: [0. 1.] |||        pred: 1 actual: 1\n",
      "pred: [0.504 0.496] actual: [1. 0.] |||        pred: 0 actual: 0\n",
      "correct: 62.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf478d",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "More of the same despite yet another model architecture.  ROC AUC of 54% and test dataset accuracy of 50%.  This leads me to believe that the dataset does not contain predictive features.\n",
    "\n",
    "To test this theory, I used another known dataset, the sonar dataset available here: https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks), actually it's up one level so that link is the dataset description.  All of the models performed significantly better in every case.  Most achieved ROC AUC of well over 70%-80% which is a significant difference.\n",
    "\n",
    "This was a very interesting experiment in which I learned a ton.  I consider these models a basic framework on which to test additional filter style deep learning models for trading.  Going forward, I intend to investigate:\n",
    "\n",
    " - Additional indicators.\n",
    " - Larger window sizes.\n",
    " - Multi-headed models which can handle different types of data (indicator head, market opening type head, market state [consolidation expansion] head).\n",
    " - Additional model architectures such as Attention, Inception, ResNet, etc.\n",
    " - Level 2 order book data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bedd7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
